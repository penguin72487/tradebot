# -*- coding: utf-8 -*-
"""
é€å¹´èµ°å‹¢ + åªç”¨éå»è³‡æ–™ GA èª¿åƒ + ç•¶å¹´èˆ‡å¾€å¾Œæ•´æ®µè©•ä¼°ï¼ˆå«å¹³è¡Œè™•ç† & é€²åº¦é¡¯ç¤ºï¼‰
- GA è©•åˆ†ï¼ˆpopulation fitnessï¼‰èˆ‡æœ€çµ‚è©•åˆ†ï¼šjoblib ä¸¦è¡Œ + tqdm é€²åº¦
- æ¯å€‹è¨“ç·´çª—å°æœªä¾†å„å¹´ï¼ˆt~endï¼‰çš„æ¨è«–ï¼šå¯é¸æ“‡ä¸¦è¡Œ + tqdm é€²åº¦
- è©³ç´°æ—¥èªŒï¼šresults_ga_roll_year/run.logï¼Œä¸¦è¼¸å‡º training_windows.csv
"""

import os
import sys
import time
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.base import clone
from sklearn.exceptions import ConvergenceWarning
from sklearn.preprocessing import StandardScaler, FunctionTransformer
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA

# ä¸¦è¡Œå·¥å…·
from joblib import Parallel, delayed

# é€²åº¦æ¢
from tqdm.auto import tqdm

# === æ¨¡å‹å€‘ï¼ˆå…ˆé è¨­ç”¨ BayesianRidgeï¼›æƒ³æ›å¯å¾€ä¸‹åŠ ï¼‰===
from sklearn.linear_model import BayesianRidge, Ridge, LinearRegression
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor
import xgboost as xgb
import catboost as cb

warnings.filterwarnings("ignore", category=ConvergenceWarning)
# ä½¿ç”¨ç›¸å°è·¯å¾‘è®€å– CSV
file_path = os.path.join(os.path.dirname(__file__), 'top200_cleaned_noname.csv')
base_dir = os.path.dirname(file_path)
result_dir = os.path.join(base_dir, 'results_ga_roll_year')
os.makedirs(result_dir, exist_ok=True)  # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨

# ---- ç°¡å–®æ—¥èªŒå™¨ï¼ˆåŒæ™‚å¯«æª”/å°å‡ºï¼‰----
import logging
log_path = os.path.join(result_dir, "run.log")
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[
        logging.FileHandler(log_path, mode='a', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
log = logging.getLogger("ga_walk_forward")

df = pd.read_csv(file_path)

# ========= åŸºç¤å‰è™•ç† =========
df['year_month'] = df['year_month'].astype(str)
df['year'] = df['year_month'].str[:4].astype(int)
df['return'] = df['return'] / 100.0
df['current_return'] = df['return'].shift(1)
df['current_return_label'] = (df['current_return'] > 0).astype(int)

# æ•¸å€¼æ¬„ä½åŸºåº•
base_features = df.drop(columns=['year_month','year','return','return_label'], errors='ignore')\
                  .select_dtypes(include=[np.number]).columns.tolist()

# å·®åˆ†æ¯”ä¾‹è®ŠåŒ–
chg_blocks = []
for col in base_features:
    prevs = {k: df[col].shift(k).replace(0, np.nan) for k in range(1, 7)}
    chg_df = pd.DataFrame({
        f"{col}_chg{k}": ((df[col] - prevs[k]) / prevs[k]).fillna(0.0)
        for k in range(1, 7)
    })
    chg_blocks.append(chg_df)

df = pd.concat([df] + chg_blocks, axis=1, copy=False)


changed_features = df.drop(columns=['year_month','year','return','return_label'], errors='ignore')\
                     .select_dtypes(include=[np.number]).columns.tolist()

# ========= è½‰æ› =========
def pca_whitening(X):
    X = np.asarray(X)
    X = SimpleImputer(strategy="median").fit_transform(X)
    return PCA(whiten=True, svd_solver="auto").fit_transform(X)

scalers = {
    'z'  : StandardScaler(),
    'pca': FunctionTransformer(pca_whitening, validate=False),
}

df = df.sort_values('year').reset_index(drop=True)
years_all = sorted(df['year'].unique())

# é€å¹´æ»¾å‹•è½‰æ›
for name, scaler in scalers.items():
    transformed_parts = []
    for y in years_all:
        fit_data = df[df['year'] <= y][changed_features]
        cur_data = df[df['year'] == y][changed_features]
        try:
            sc = clone(scaler)
            sc.fit(fit_data)
            cur_tr = sc.transform(cur_data)
            cur_tr = pd.DataFrame(cur_tr, index=cur_data.index,
                                  columns=[f'{c}_{name}' for c in changed_features])
            transformed_parts.append(cur_tr)
        except Exception as e:
            log.warning(f'[{name}] year={y} è½‰æ›å¤±æ•—: {e}')
    if transformed_parts:
        transformed_all = pd.concat(transformed_parts).sort_index()
        df = pd.concat([df, transformed_all], axis=1)

# å¯ç”¨ç‰¹å¾µ
exclude_cols = ['year_month','year','return','return_label','current_return','current_return_label']
all_features = df.drop(columns=[c for c in exclude_cols if c in df.columns])\
                 .select_dtypes(include=[np.number]).columns.tolist()

# å»æ‰é¦–å°¾å¹´
years = years_all[1:-1]
df = df[df['year'].isin(years)].copy()
years = sorted(df['year'].unique())

log.info('æ¯å¹´æ¨£æœ¬æ•¸ï¼ˆè‚¡ç¥¨æ•¸ï¼‰ï¼š\n' + str(df.groupby('year')['stock_id'].nunique()))

# ========= ç­–ç•¥è¨ˆç®— =========
TOP_NS = [10, 20, 30, 200]
KINDs  = ['long','short','long_short']

def year_strategy_returns(test_df, pred_col='predicted_return'):
    res = {n: {} for n in TOP_NS}
    for n in TOP_NS:
        n_eff = min(n, len(test_df))
        if n_eff <= 0:
            for kind in KINDs:
                res[n][kind] = np.nan
            continue
        top_n    = test_df.nlargest(n_eff, pred_col)
        bottom_n = test_df.nsmallest(n_eff, pred_col)

        long_ret  = top_n['true_return'].mean()
        short_ret = - bottom_n['true_return'].mean()
        long_short = (long_ret + short_ret) / 2.0

        res[n]['long'] = float(long_ret)
        res[n]['short'] = float(short_ret)
        res[n]['long_short'] = float(long_short)
    return res

def fit_predict_one_year(model, train_df, test_df, feat_cols):
    Xtr, ytr = train_df[feat_cols], train_df['return']
    Xte, yte = test_df[feat_cols], test_df['return']

    m = clone(model)
    try:
        m.fit(Xtr, ytr)
        preds = m.predict(Xte)
    except Exception:
        return None, None
    out = test_df[['year']].copy()
    out['true_return'] = yte.values
    out['predicted_return'] = preds
    return m, out

def cumulative_score(series_list):
    vals = [x for x in series_list if pd.notna(x)]
    if not vals:
        return 0.0
    cum = np.cumprod([1.0 + v for v in vals])[-1]
    return float(cum)

# ========= å¯åˆ‡æ›æ¨¡å‹èˆ‡åƒæ•¸ç©ºé–“ =========
MODELS = {
    'BayesianRidge': BayesianRidge
}

PARAM_SPACES = {
    'BayesianRidge': {
        'max_iter'     : (100, 500),
        'tol'          : (1e-6, 1e-2),
        'alpha_1'      : (1e-7, 1e1),
        'alpha_2'      : (1e-7, 1e1),
        'lambda_1'     : (1e-7, 1e1),
        'lambda_2'     : (1e-7, 1e1),
        'fit_intercept': [True, False],
        'compute_score': [True, False],
        'copy_X'       : [True, False],
    },
}

def init_model_by_name(name, params):
    if name == 'BayesianRidge':
        return BayesianRidge(**params)
    elif name == 'Ridge':
        return Ridge(**params)
    elif name == 'SVR':
        return SVR(**params)
    elif name == 'RandomForest':
        return RandomForestRegressor(**params)
    elif name == 'ExtraTrees':
        return ExtraTreesRegressor(**params)
    elif name == 'XGB':
        return xgb.XGBRegressor(**params)
    elif name == 'CatBoost':
        return cb.CatBoostRegressor(verbose=0, **params)
    elif name == 'Linear':
        return LinearRegression(**params)
    else:
        raise ValueError(f'æœªçŸ¥æ¨¡å‹: {name}')

# ========= GAï¼ˆå«å¹³è¡Œ & é€²åº¦ï¼‰=========
rng = np.random.default_rng(42)

def decode_params(space, gene):  # gene: [0,1]^D
    decoded = {}
    i = 0
    for k, v in space.items():
        if isinstance(v, tuple):
            lo, hi = v
            g = float(gene[i])
            decoded[k] = lo + g * (hi - lo)
            if isinstance(lo, int) and isinstance(hi, int):
                decoded[k] = int(round(decoded[k]))
            i += 1
        elif isinstance(v, list):
            g = float(gene[i])
            idx = int(np.floor(g * len(v))) % len(v)
            decoded[k] = v[idx]
            i += 1
        else:
            raise ValueError('param space åƒ…æ”¯æ´ tuple/list')
    return decoded

def build_gene_dim(space):
    return sum(1 for _ in space.items())

# --- checkpoint utils ---
import pickle

def save_checkpoint(path, data):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "wb") as f:
        pickle.dump(data, f)

def load_checkpoint(path):
    with open(path, "rb") as f:
        return pickle.load(f)

# === æ–°å¢ï¼šGA å…§éƒ¨å¯è¦–åŒ–ï¼ˆç•« inner_years çš„ç´¯ç©æ›²ç·šï¼‰===
def _plot_ga_inner_curves(traj, inner_years, out_dir, tag, viz_kinds=('long','short','long_short')):
    """
    traj: {n:{kind:[r_t,...]}} ä¾†è‡ª evaluate_gene_traj
    æœƒå„åˆ¥è¼¸å‡º Top10/20/30/200 çš„åœ–ç‰‡ï¼›æ¯å¼µåœ–å« long/short/long_short ä¸‰æ¢ç·š
    """
    os.makedirs(out_dir, exist_ok=True)
    years_axis = inner_years[1:]  # ç¬¬ä¸€å€‹å¹´æ˜¯ç”¨ä¾†è¨“ç·´ï¼Œæ‰€ä»¥åºåˆ—å¾ç¬¬äºŒå€‹å¹´é–‹å§‹
    for n in sorted(traj.keys()):
        plt.figure(figsize=(12, 7))
        best_end = -np.inf
        best_label = ""
        for kind in viz_kinds:
            seq = [x for x in traj[n][kind] if pd.notna(x)]
            cum = np.cumprod([1.0 + (v if pd.notna(v) else 0.0) for v in seq]) if seq else np.array([])
            label = f'{kind.capitalize()} Top{n}'
            if len(cum) > 0:
                plt.plot(years_axis[:len(cum)], cum, marker='o', linestyle='-' if kind=='long' else ('--' if kind=='short' else ':'), label=label)
                if cum[-1] > best_end:
                    best_end = float(cum[-1]); best_label = label

        plt.title(f'GA {tag} â€“ Top{n} (Best: {best_label} {best_end:.2f}Ã—)' if best_end>0 else f'GA {tag} â€“ Top{n}')
        plt.xlabel('Year'); plt.ylabel('Cumulative (Ã—)')
        plt.yscale('log'); plt.grid(True); plt.legend()
        fname = os.path.join(out_dir, f'GA_{tag}_Top{n}.png')
        plt.tight_layout()
        plt.savefig(fname)
        plt.close()


def _plot_window_all_in_one(
    train_span, test_year, inner_years,
    inner_traj,                     # dict: {TopN:{kind:[r_t,...]}}
    future_years,                   # list: [t, t+1, ...]
    future_returns_seq,             # dict: {TopN:{kind:[r_t, r_{t+1}, ...]}}
    out_dir,                        # è¼¸å‡ºç›®éŒ„
    fname_prefix="window",
    kinds=('long','short','long_short'),
    top_ns=(10,20,30,200)
):
    """
    ç”¢å‡º 1 å¼µ 3x3 åœ–ï¼š
      æ¯è¡Œ=kindï¼›æ¯åˆ—åˆ†åˆ¥æ˜¯ [Inner ç´¯ç©, Forward ç´¯ç©, Forward å¹´åŒ–(èµ·é» t èˆ‡ t+1)]
    - inner_traj: ä¾†è‡ª evaluate_gene_traj çš„å›å‚³
    - future_returns_seq: ä½ åœ¨ä¸»æµç¨‹çµ„å¥½çš„ future_returnsï¼ˆæŠŠ NaN æ› 0 å†ç´¯ä¹˜ï¼‰
    """
    os.makedirs(out_dir, exist_ok=True)

    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(18, 12), constrained_layout=True)
    # æŠŠ kinds å›ºå®šé †åºå°æ‡‰åˆ° row
    kind_rows = {k:i for i,k in enumerate(kinds)}
    col_titles = ["Inner cumulative (Ã—)", f"Forward cumulative from {test_year} (Ã—)",
                  f"Annualized: {test_year}â†’end & {test_year+1}â†’end"]

    # 1) Inner cumulative
    x_inner = inner_years[1:]  # inner fitness å¾ç¬¬äºŒå€‹å¹´é–‹å§‹
    for k in kinds:
        r = kind_rows[k]
        ax = axes[r, 0]
        for n in top_ns:
            seq = inner_traj.get(n, {}).get(k, [])
            if len(seq) == 0:
                continue
            cum = np.cumprod([1.0 + (v if pd.notna(v) else 0.0) for v in seq])
            ax.plot(x_inner[:len(cum)], cum, marker='o', label=f"Top{n}")
        ax.set_title(f"{k} â€“ {col_titles[0]}")
        ax.set_yscale('log')
        ax.grid(True)
        if r == len(kinds)-1:
            ax.set_xlabel("Year")
        ax.set_ylabel("Ã—")
        ax.legend()

    # 2) Forward cumulative (å›ºå®šæ¨¡å‹ from test_year)
    x_fwd = future_years
    for k in kinds:
        r = kind_rows[k]
        ax = axes[r, 1]
        for n in top_ns:
            seq = future_returns_seq.get(n, {}).get(k, [])
            if len(seq) == 0:
                continue
            cum = np.cumprod([1.0 + (v if pd.notna(v) else 0.0) for v in seq])
            ax.plot(x_fwd[:len(cum)], cum, marker='o', label=f"Top{n}")
        ax.set_title(f"{k} â€“ {col_titles[1]}")
        ax.set_yscale('log')
        ax.grid(True)
        if r == len(kinds)-1:
            ax.set_xlabel("Year")
        ax.set_ylabel("Ã—")
        ax.legend()

    # 3) Annualized curvesï¼ˆåƒ…èµ·é» tï¼‰
    for k in kinds:
        r = kind_rows[k]
        ax = axes[r, 2]
        for n in top_ns:
            seq = future_returns_seq.get(n, {}).get(k, [])
            seq = [0.0 if not pd.notna(v) else v for v in seq]
            if len(seq) == 0:
                continue
            # èµ·é» t
            cum = np.cumprod([1.0 + v for v in seq])
            years_span = np.arange(1, len(seq)+1)
            ann_t = np.power(cum, 1.0/years_span) - 1.0
            ax.plot(x_fwd[:len(ann_t)], ann_t, label=f"Top{n} (start {test_year})")

        ax.set_title(f"{k} â€“ Annualized: {test_year}â†’end")
        ax.grid(True)
        if r == len(kinds)-1:
            ax.set_xlabel("Year")
        ax.set_ylabel("annualized")
        ax.legend()

    fig.suptitle(f"Train {train_span}  |  Test from {test_year}", fontsize=14)
    out_path = os.path.join(out_dir, f"{fname_prefix}_{train_span}_T{test_year}.png")
    fig.savefig(out_path, dpi=140)
    plt.close(fig)
    return out_path




def ga_optimize_params(
    model_name,
    train_df,
    feat_cols,
    inner_years,
    population=128,
    generations=200,
    cx_prob=0.85,
    init_mut_prob=0.10,
    improve_delta=1e-4,
    early_stop_patience=10,
    enable_feature_selection=True,
    init_density=0.05,
    n_jobs=-1,
    backend='loky',
    checkpoint_dir=None,
    resume=True,
    checkpoint_every=5,
    progress_desc="GA",
    log=print,
    # === æ–°å¢ä¸‰å€‹ ===
    viz_on_improve=True,
    viz_every=1,
    viz_dir=None,                        # è‹¥ None å‰‡ç”¨ checkpoint_dir æˆ– result_dir ä¸‹çš„ "ga_viz"
    viz_kinds=('long','short','long_short'),
     # === æ–°å¢ï¼šæ¯ä»£æ¢æŸ¥ä¸‹ä¸€å¹´ OOSï¼ˆæ—¥èªŒç”¨ï¼Œä¸åƒèˆ‡é¸æ“‡ï¼‰===
    next_year_df=None,           # å¤–å±¤å‚³é€²ä¾†çš„ test_dfï¼ˆä¸‹ä¸€å¹´ï¼‰
    oos_probe=True,              # æ˜¯å¦å•Ÿç”¨æ¯ä»£ OOS æ¢æŸ¥
    oos_every=1,                 # æ¯å¹¾ä»£åšä¸€æ¬¡ï¼ˆ1=æ¯ä»£ï¼Œçœæ™‚é–“å¯è¨­ 5/10ï¼‰
    oos_metric=('10', 'long_short'),  # è¦æ‰“å°å“ªå€‹æŒ‡æ¨™ï¼ˆTopN, kindï¼‰
):

    """
    ä»¥ inner_years åš expanding walk-forward ç•¶ fitnessã€‚
    è‹¥ enable_feature_selection=True:
        åŸºå›  = [ feature_bits (len=F), param_genes (len=P) ]
      å…¶ä¸­ feature_bits âˆˆ {0,1}ï¼Œparam_genes âˆˆ [0,1]
    å¦å‰‡ï¼ˆåªèª¿åƒæ•¸ï¼‰:
        åŸºå›  = [ param_genes (len=P) ]
    å‹•æ…‹çªè®Šç‡ï¼š
        ä¾ no_improvement_count èª¿æ•´ï¼Œåƒè€ƒä½ çµ¦çš„è¦å‰‡ï¼Œä¸¦å€åˆ†
        - ç‰¹å¾µä½å…ƒï¼šç”¨ bit-flip æ¦‚ç‡
        - åƒæ•¸ä½å…ƒï¼šåŠ é«˜æ–¯å™ªéŸ³ä¸¦ clip åˆ° [0,1]
    """
    space = PARAM_SPACES[model_name]

    # ---- åŸºå› é•·åº¦ ----
    param_dim = sum(1 for _ in space.items())
    F = len(feat_cols) if enable_feature_selection else 0
    P = param_dim
    D = F + P

    # ---- åŸºå› åˆå§‹åŒ– ----
    rng_local = np.random.default_rng(42)  # å›ºå®šé€™å±¤çš„éš¨æ©Ÿæ€§ï¼Œä¾¿æ–¼é‡ç¾
    def init_population(n):
        if enable_feature_selection:
            # ç‰¹å¾µä½å…ƒï¼šä¾å¯†åº¦ç”¢ç”Ÿ 0/1
            feature_bits = (rng_local.random((n, F)) < init_density).astype(np.float64)
            # åƒæ•¸ä½å…ƒï¼š[0,1] å‡å‹»
            param_genes = rng_local.random((n, P))
            return np.concatenate([feature_bits, param_genes], axis=1)
        else:
            return rng_local.random((n, P))

    # ---- åŸºå› è§£ç¢¼ ----
    def decode_params(space, gene_param_part):
        decoded = {}
        i = 0
        for k, v in space.items():
            g = float(gene_param_part[i])
            if isinstance(v, tuple):
                lo, hi = v
                val = lo + g * (hi - lo)
                if isinstance(lo, int) and isinstance(hi, int):
                    val = int(round(val))
                decoded[k] = val
            elif isinstance(v, list):
                idx = int(np.floor(g * len(v))) % len(v)
                decoded[k] = v[idx]
            else:
                raise ValueError('param space åƒ…æ”¯æ´ tuple/list')
            i += 1
        return decoded

    # ---- fitness ----
    def fitness_one(gene):
        # è§£æç‰¹å¾µ
        if enable_feature_selection:
            bits = gene[:F] >= 0.5
            sel_cols = [c for c, b in zip(feat_cols, bits) if b]
            # è‡³å°‘ä¿åº• 1 å€‹ç‰¹å¾µï¼Œå¦å‰‡ç›´æ¥ 0 åˆ†
            if len(sel_cols) == 0:
                return 0.0, None, None
        else:
            sel_cols = feat_cols

        # è§£æåƒæ•¸
        params = decode_params(space, gene[-P:])
        model  = init_model_by_name(model_name, params)
        traj = {n:{k:[] for k in KINDs} for n in TOP_NS}

        # expanding walk-forward
        for i in range(1, len(inner_years)):
            tr_years = inner_years[:i]
            te_year  = inner_years[i]
            tr_df = train_df[train_df['year'].isin(tr_years)]
            te_df = train_df[train_df['year'] == te_year]
            if te_df.empty or tr_df.empty:
                continue

            m, pred = fit_predict_one_year(model, tr_df, te_df, sel_cols)
            if m is None:
                continue
            one = year_strategy_returns(pred, 'predicted_return')
            for n in TOP_NS:
                for kind in KINDs:
                    traj[n][kind].append(one[n][kind])

        # åˆ†æ•¸ = æœ€ä½³ (n, kind) çš„ç´¯ä¹˜çµ‚å€¼
        best = 0.0
        for n in TOP_NS:
            for kind in KINDs:
                seq = [x for x in traj[n][kind] if pd.notna(x)]
                if seq:
                    score = np.prod([1.0 + v for v in seq])
                    if score > best:
                        best = score
        return best, sel_cols, params
    
        # --- é‡å°æŸå€‹åŸºå› ï¼Œå›ç®— inner_years çš„å®Œæ•´è»Œè·¡ï¼ˆç”¨æ–¼å‡ºåœ–ï¼‰ ---
    def evaluate_gene_traj(gene):
        # è§£æç‰¹å¾µ
        if enable_feature_selection:
            bits = gene[:F] >= 0.5
            sel_cols = [c for c, b in zip(feat_cols, bits) if b]
            if len(sel_cols) == 0:
                return {n:{k:[] for k in KINDs} for n in TOP_NS}
        else:
            sel_cols = feat_cols

        params = decode_params(space, gene[-P:])
        model  = init_model_by_name(model_name, params)
        traj = {n:{k:[] for k in KINDs} for n in TOP_NS}
        for i in range(1, len(inner_years)):
            tr_years = inner_years[:i]
            te_year  = inner_years[i]
            tr_df = train_df[train_df['year'].isin(tr_years)]
            te_df = train_df[train_df['year'] == te_year]
            if te_df.empty or tr_df.empty:
                for n in TOP_NS:
                    for k in KINDs:
                        traj[n][k].append(np.nan)
                continue
            m, pred = fit_predict_one_year(model, tr_df, te_df, sel_cols)
            if m is None:
                for n in TOP_NS:
                    for k in KINDs:
                        traj[n][k].append(np.nan)
                continue
            one = year_strategy_returns(pred, 'predicted_return')
            for n in TOP_NS:
                for k in KINDs:
                    traj[n][k].append(one[n][k])
        return traj


    # ---- checkpoint æ¢å¾© ----
    start_gen = 0
    best_score = -np.inf
    best_cols = None
    best_params = None
    no_improve = 0

    if checkpoint_dir:
        ckpt_path = os.path.join(checkpoint_dir, f"{model_name}.pkl")
    else:
        ckpt_path = None

    if ckpt_path and resume and os.path.exists(ckpt_path):
        ckpt = load_checkpoint(ckpt_path)
        pop = ckpt["population"]
        start_gen = ckpt["generation"]
        best_score = ckpt["best_score"]
        best_cols = ckpt["best_cols"]
        best_params = ckpt["best_params"]
        no_improve = ckpt.get("no_improve", 0)
        log(f"ğŸ”„ æ¢å¾© GA checkpoint: gen={start_gen}, best={best_score:.4f}")
    else:
        pop = init_population(population)

    # ---- ä¸»è¦å¾ªç’° ----
    pbar = tqdm(range(start_gen, generations), desc=progress_desc, leave=False, ncols=100)
    for gen in pbar:
        # ä¸¦è¡Œè¨ˆåˆ†
        evals = Parallel(n_jobs=n_jobs, backend=backend, prefer="processes")(
            delayed(fitness_one)(ind) for ind in pop
        )
        scores = np.array([e[0] for e in evals], dtype=float)

        # é€™ä»£æœ€å„ª
        gen_best_idx = int(np.nanargmax(scores)) if len(scores) else 0
        gen_best = float(scores[gen_best_idx]) if len(scores) else 0.0
        pbar.set_postfix(best=f"{gen_best:.4f}", no_improve=no_improve)

        # æª¢æŸ¥æ˜¯å¦é€²æ­¥
        if (gen_best - best_score) <= improve_delta:
            no_improve += 1
        else:
            no_improve = 0
            best_score = gen_best
            best_cols = evals[gen_best_idx][1]
            best_params = evals[gen_best_idx][2]

        # æ—©åœ
        if no_improve >= early_stop_patience:
            log(f"â¹ï¸ æ—©åœæ–¼ç¬¬ {gen+1} ä»£ï¼ˆé€£çºŒ {no_improve} ä»£ç„¡æå‡ï¼‰")
            # ä¿å­˜åœä¸‹ä¾†æ™‚çš„ checkpoint
            if ckpt_path:
                save_checkpoint(ckpt_path, {
                    "population": pop,
                    "generation": gen + 1,
                    "best_score": best_score,
                    "best_cols": best_cols,
                    "best_params": best_params,
                    "no_improve": no_improve
                })
            break

        # --- é¸æ“‡ï¼ˆè¼ªç›¤ï¼‰---
        s = scores.copy()
        s[~np.isfinite(s)] = 0.0
        total = s.sum()
        if total <= 0:
            probs = np.ones_like(s) / len(s)
        else:
            probs = s / total
        idx = rng.choice(len(pop), size=len(pop), replace=True, p=probs)
        mates = pop[idx]

        # --- äº¤é… ---
        next_pop = np.empty_like(pop)
        for i in range(0, len(mates), 2):
            p1 = mates[i]
            p2 = mates[(i+1) % len(mates)]
            if rng.random() < cx_prob:
                cp = rng.integers(1, D)
                c1 = np.concatenate([p1[:cp], p2[cp:]])
                c2 = np.concatenate([p2[:cp], p1[cp:]])
            else:
                c1, c2 = p1.copy(), p2.copy()
            next_pop[i] = c1
            next_pop[(i+1) % len(mates)] = c2

        # --- å‹•æ…‹çªè®Šç‡ï¼ˆä¾ no_improveï¼‰---
        # åƒè€ƒä½ æä¾›çš„è¦å‰‡ï¼Œå»¶ä¼¸åˆ° param/feature å…©æ®µ
        if no_improve >= 100:
            mut_intensity = 1 + no_improve
        elif no_improve >= 20:
            mut_intensity = 1 + no_improve / 20.0
        elif no_improve >= 5:
            mut_intensity = init_mut_prob + ((0.8 - init_mut_prob) * (1 - no_improve / 20.0))
        else:
            mut_intensity = init_mut_prob

        # é™åˆ¶åˆ°åˆç†å€é–“ï¼ˆé¿å…çˆ†æ‰ï¼‰
        mut_intensity = float(np.clip(mut_intensity, 0.0, 1.0))

        # ç‚ºäº†è®“ã€Œæ•´é«”è®Šç•°æ¯”ä¾‹ã€èˆ‡ç¶­åº¦ç„¡é—œï¼Œæ¡ per-gene æ©Ÿç‡ = mut_intensity / D
        per_gene_p = mut_intensity / max(D, 1)

        # --- çªè®Šï¼šç‰¹å¾µä½å…ƒ flipï¼›åƒæ•¸ä½å…ƒåŠ å™ªéŸ³ ---
        for i in range(len(next_pop)):
            if enable_feature_selection and F > 0:
                # feature bits: Bernoulli flip
                flip_mask = rng.random(F) < per_gene_p
                next_pop[i, :F][flip_mask] = 1.0 - next_pop[i, :F][flip_mask]
            # param genes: add gaussian noise then clip
            noise_mask = rng.random(P) < per_gene_p
            noise = rng.normal(0.0, 0.10, size=P)   # å¯è¦–éœ€è¦æŠŠ 0.10 åšæˆåƒæ•¸
            vec = next_pop[i, -P:]
            vec[noise_mask] = np.clip(vec[noise_mask] + noise[noise_mask], 0.0, 1.0)
            next_pop[i, -P:] = vec

        pop = next_pop

        # --- checkpointï¼ˆæ¯éš” checkpoint_every ä»£ & æœ€å¾Œä¸€ä»£ï¼‰---
        if ckpt_path and ((gen + 1) % checkpoint_every == 0):
            save_checkpoint(ckpt_path, {
                "population": pop,
                "generation": gen + 1,
                "best_score": best_score,
                "best_cols": best_cols,
                "best_params": best_params,
                "no_improve": no_improve
            })
        
        # ---ï¼ˆæ–°å¢ï¼‰æ¢æŸ¥ä¸‹ä¸€å¹´ OOSï¼šåªåšæ—¥èªŒï¼Œä¸å½±éŸ¿ GA æ±ºç­– ---
        
        oos_msg = ""
        if oos_probe and (next_year_df is not None) and ((gen + 1) % max(1, oos_every) == 0):
            try:
                # ä»¥è©²ä»£æœ€ä½³å€‹é«”çš„ç‰¹å¾µé¸æ“‡
                if enable_feature_selection and F > 0:
                    bits = pop[gen_best_idx][:F] >= 0.5
                    sel_cols_probe = [c for c, b in zip(feat_cols, bits) if b]
                    # ä¿åº•ï¼Œé¿å… 0 ç‰¹å¾µ
                    if len(sel_cols_probe) == 0:
                        sel_cols_probe = feat_cols
                else:
                    sel_cols_probe = feat_cols

                # ä»¥ç•¶å‰æœ€ä½³åƒæ•¸é‡å»ºæ¨¡å‹ï¼Œä½¿ç”¨å®Œæ•´ inner_years çš„ train_df ä¾† fit
                params_probe = decode_params(space, pop[gen_best_idx][-P:])
                model_probe  = init_model_by_name(model_name, params_probe)
                m_probe, pred_next = fit_predict_one_year(model_probe, train_df, next_year_df, sel_cols_probe)

                if (m_probe is not None) and (pred_next is not None):
                    r_next = year_strategy_returns(pred_next)
                    tn, kd = oos_metric  # e.g. ('10','long_short')
                    oos_val = r_next[int(tn)][kd]
                    oos_msg = f" | nextY_OOS(Top{tn}/{kd})={oos_val:+.4f}"
                else:
                    oos_msg = " | nextY_OOS=NaN"
            except Exception:
                oos_msg = " | nextY_OOS=ERR"


        # é¡¯ç¤ºç´°ç¯€
        if enable_feature_selection:
            # å–å‡ºç›®å‰æœ€ä½³å€‹é«”çš„ç‰¹å¾µä½å…ƒ
            bits = pop[gen_best_idx][:F] >= 0.5
            sel_cols_current = [c for c, b in zip(feat_cols, bits) if b]
            sel_count = len(sel_cols_current)

            preview = ", ".join(sel_cols_current)

            log(
                f"Gen {gen+1:04d} | best={best_score:.4f} | no_imp={no_improve:02d} | "
                f"{oos_msg or ' | nextY_OOS=N/A'}"
                f"mut={mut_intensity:.4f} | sel_features={sel_count} "
                f"[{preview}] | best_params={best_params}"
            )
        else:
            log(
                f"Gen {gen+1:04d} | best={best_score:.4f} | no_imp={no_improve:02d} | "
                f"mut={mut_intensity:.4f} | sel_features={sel_count} "
            )
        # ï¼ˆå¯é¸ï¼‰æŠŠæ¯ä»£æœ€ä½³ç‰¹å¾µåå–®å­˜æª”ï¼Œä¾¿æ–¼è¿½è¹¤
        try:
            if checkpoint_dir:
                path = os.path.join(checkpoint_dir, f"sel_features_gen{gen+1:04d}.txt")
                with open(path, "w", encoding="utf-8") as f:
                    f.write("\n".join(sel_cols_current))
        except Exception:
            pass

    pbar.close()

    # æ”¶å°¾ï¼šç¢ºä¿æœ€å¾Œ checkpoint
    if ckpt_path:
        save_checkpoint(ckpt_path, {
            "population": pop,
            "generation": min(generations, (gen if 'gen' in locals() else 0) + 1),
            "best_score": best_score,
            "best_cols": best_cols,
            "best_params": best_params,
            "no_improve": no_improve
        })

    # === æ¯ä»£å›ºå®šå‡ºåœ–ï¼ˆä¾ viz_every æ§åˆ¶é »ç‡ï¼‰===
    if (gen + 1) % max(1, viz_every) == 0:
        tag = f"{progress_desc.replace(' ', '_')}_gen{gen+1:04d}"
        out_dir = (viz_dir or checkpoint_dir or os.path.join(os.path.dirname(__file__), 'results_ga_roll_year', 'ga_viz'))
        try:
            # ä»¥è©²ä»£æœ€ä½³å€‹é«”ç¹ªåœ–
            traj = evaluate_gene_traj(pop[gen_best_idx])
            _plot_ga_inner_curves(traj, inner_years, out_dir, tag, viz_kinds=viz_kinds)
            log(f"ğŸ“ˆ [viz] å·²è¼¸å‡ºï¼š{out_dir}/GA_{tag}_Top(10|20|30|200).png")
        except Exception as e:
            log(f"âš ï¸ [viz] ç”Ÿæˆå¤±æ•—ï¼ˆgen {gen+1}ï¼‰ï¼š{e}")

    # åœ¨å¤–å±¤ï¼Œæ‹¿åˆ° best_cols å¾Œï¼ˆæŸä¸€å€‹è¨“ç·´çª—çš„æœ€çµ‚çµæœï¼‰
    if best_cols is not None and ckpt_dir:
        out_feats = os.path.join(ckpt_dir, "best_selected_features.txt")
        with open(out_feats, "w", encoding="utf-8") as f:
            f.write("\n".join(best_cols))

    # å›å‚³æœ€ä½³
    if enable_feature_selection:
        return best_params, best_score, (best_cols if best_cols is not None else feat_cols)
    else:
        return best_params, best_score, None


# ========= ä¸»æµç¨‹ï¼šé€å¹´ =========
MODEL_NAME = 'BayesianRidge'
FEATURES   = all_features

# ä¸¦è¡Œé¸é …
GA_N_JOBS = -1          # GA fitness ä¸¦è¡Œæ ¸æ•¸
FWD_N_JOBS = -1         # é‡å°æœªä¾†å„å¹´çš„æ¨è«–æ˜¯å¦ä¸¦è¡Œï¼ˆ-1=å…¨éƒ¨ï¼›è¨­ 1 å‰‡é—œé–‰ï¼‰
FWD_BACKEND = 'loky'    # å¤šé€²ç¨‹

# 1) é€å¹´ OOS
oos_traj = {n:{k:[] for k in KINDs} for n in TOP_NS}
oos_years = []

# 2) è¨“ç·´çª—â†’æ•´æ®µå¹´åŒ–
forward_summary_rows = []

min_years_needed = 3

# ç”¨æ–¼å½™ç¸½æ¯å€‹è¨“ç·´çª—çš„é‡é»ï¼Œæœ€å¾Œå¦å­˜ CSV
training_rows = []

outer_pbar = tqdm(range(1, len(years)), desc="Walk-forward years", ncols=100)
for i in outer_pbar:
    train_years = years[:i]      # <= t-1
    test_year   = years[i]       # t
    if len(train_years) < min_years_needed:
        continue

    train_df = df[df['year'].isin(train_years)]
    test_df  = df[df['year'] == test_year]

    # === GA è¶…åƒæ•¸ ===
    # === GA è¶…åƒæ•¸ï¼ˆæœ‰ checkpoint/æ—©åœ/åˆå§‹å¯†åº¦/å‹•æ…‹çªè®Šç‡/ç‰¹å¾µé¸æ“‡ï¼‰===
    train_start, train_end = train_years[0], train_years[-1]
    ckpt_dir = os.path.join(result_dir, "ckpt", f"{train_start}-{train_end}")
    next_year_df = df[df['year'] == years[i+1]] if (i + 1) < len(years) else None

    desc = f"GA {train_start}-{train_end}"
    best_params, best_fit, best_cols = ga_optimize_params(
        model_name=MODEL_NAME,
        train_df=train_df,
        feat_cols=FEATURES,            # è‹¥è¦åŒæ™‚åšç‰¹å¾µé¸æ“‡ï¼Œå¯åœ¨ä¸‹æ–¹æŠŠ enable_feature_selection=True
        inner_years=train_years,
        # --- GA è¦æ¨¡/ä»£æ•¸ ---
        population=1024,
        generations=1000,
        # --- äº¤é…/åˆå§‹çªè®Šç‡ ---
        cx_prob=0.85,
        init_mut_prob=0.12,            # ä½ åŸæœ¬çš„ mut_prob æ”¹åç‚º init_mut_prob
        # --- æ—©åœ ---
        improve_delta=1e-4,
        early_stop_patience=50,  # é€£çºŒ 20 ä»£ç„¡æå‡å°±æ—©åœ
        # --- ç‰¹å¾µé¸æ“‡ï¼ˆæƒ³é–‹å°± Trueï¼‰---
        enable_feature_selection=True,  # æ˜¯å¦åŒæ™‚åšç‰¹å¾µé¸æ“‡
        init_density=0.05,             # ç‰¹å¾µ bit åˆå§‹ 1 çš„å¯†åº¦
        # --- ä¸¦è¡Œ ---
        n_jobs=GA_N_JOBS,
        backend='loky',
        # --- checkpoint ---
        checkpoint_dir=ckpt_dir,
        resume=True,                   # æœ‰ ckpt å°±çºŒè·‘
        checkpoint_every=5,            # æ¯å¹¾ä»£å­˜ä¸€æ¬¡
        # --- é¡¯ç¤º ---
        progress_desc=desc,
        log=log.info,
        next_year_df=next_year_df,
        oos_probe=True,
        oos_every=1,   
    )
    log.info(
        f'[GA] Train {train_start}-{train_end} -> best_score={best_fit:.4f}, params={best_params}'
        + (f', selected_features={len(best_cols)}' if best_cols is not None else '')
    )

    log.info(f'[GA] Train {train_years[0]}-{train_years[-1]} -> best_score={best_fit:.4f}, params={best_params}')

    # === ç”¨æœ€ä½³åƒæ•¸è¨“ç·´å›ºå®šæ¨¡å‹ ===
    base_model = init_model_by_name(MODEL_NAME, best_params)
    cols_for_this_window = (best_cols if best_cols is not None else FEATURES)
    m, pred_t = fit_predict_one_year(base_model, train_df, test_df, cols_for_this_window)

    if (m is None) or (pred_t is None):
        log.warning(f"[SKIP] {test_year} ç”±æ–¼æ¨¡å‹è¨“ç·´/é æ¸¬å¤±æ•—")
        continue

    # (A) OOSï¼šç•¶å¹´ t
    one_t = year_strategy_returns(pred_t)
    for n in TOP_NS:
        for kind in KINDs:
            oos_traj[n][kind].append(one_t[n][kind])
    oos_years.append(test_year)

    # ç›®å‰ OOS ç´¯ç©ï¼ˆä»¥ Top10/long_short åšä¸»æŒ‡æ¨™ï¼‰
    oos_seq = [x if pd.notna(x) else 0.0 for x in oos_traj[10]['long_short']]
    oos_cum = float(np.prod([1.0 + v for v in oos_seq]))
    outer_pbar.set_postfix(year=test_year, oos_top10_ls=f"{oos_cum:.2f}x")

    # (B) Forwardï¼št ~ end
    future_years = years[i:]  # å¾ t åˆ°æœ€å¾Œ

    def infer_one_future_year(fy):
        fy_df = df[df['year'] == fy]
        Xte, yte = fy_df[cols_for_this_window], fy_df['return']
        preds = m.predict(Xte)  # å›ºå®šæ¨¡å‹ï¼Œä¸é‡è¨“
        te = fy_df[['year']].copy()
        te['true_return'] = yte.values
        te['predicted_return'] = preds
        return year_strategy_returns(te)

    # é‡å°æœªä¾†å„å¹´æ¨è«–çš„é€²åº¦åˆ—
    fut_iter = future_years if FWD_N_JOBS == 1 else tqdm(future_years, desc=f"Forward {test_year}â†’end", leave=False, ncols=100)

    if FWD_N_JOBS == 1:
        future_returns_list = [infer_one_future_year(fy) for fy in fut_iter]
    else:
        # å…ˆç‚ºäº†é¡¯ç¤ºé€²åº¦ï¼ŒæŠŠå¹´ä»½å±•é–‹ï¼Œä¸¦è¡Œ + æ‰‹å‹•æ›´æ–°é€²åº¦
        def _wrap(fy):
            res = infer_one_future_year(fy)
            return (fy, res)

        # ç”¨ Parallel ä¸¦è¡Œå¾Œï¼Œå†æŒ‰åŸé †åºèšåˆ
        future_returns_list = Parallel(n_jobs=FWD_N_JOBS, backend=FWD_BACKEND, prefer="processes")(
            delayed(infer_one_future_year)(fy) for fy in future_years
        )
        if isinstance(fut_iter, tqdm):
            fut_iter.close()

    # èšåˆ
    future_returns = {n:{k:[] for k in KINDs} for n in TOP_NS}
    for yr_res in future_returns_list:
        for n in TOP_NS:
            for kind in KINDs:
                future_returns[n][kind].append(yr_res[n][kind])

    # ç®—æ•´æ®µç´¯ç© & å¹´åŒ–
    span = len(future_years)
    row = {
        'TrainYears' : f'{train_years[0]}-{train_years[-1]}',
        'TestSpan'   : f'{future_years[0]}-{future_years[-1]}',
        'Params'     : repr(best_params)
    }
    for n in TOP_NS:
        for kind in KINDs:
            seq = [x for x in future_returns[n][kind] if pd.notna(x)]
            if len(seq) == 0:
                row[f'Top{n}_{kind}_Cumulative'] = np.nan
                row[f'Top{n}_{kind}_Annual'] = np.nan
            else:
                cum = np.prod([1.0 + v for v in seq]) - 1.0
                ann = ( (1.0 + cum)**(1.0 / span) - 1.0 ) if (1.0 + cum) > 0 else np.nan
                row[f'Top{n}_{kind}_Cumulative'] = round(float(cum), 6)
                row[f'Top{n}_{kind}_Annual']     = round(float(ann), 6)
    forward_summary_rows.append(row)

    # ---- ç•¶è¼ªæ‘˜è¦ï¼ˆé—œéµæ•¸å­—ï¼‰----
    key_yr_ret = one_t[10]['long_short']  # ç•¶å¹´ Top10 long_short
    key_forward_ann = row.get('Top10_long_short_Annual', np.nan)
    log.info(
        f"[{train_years[0]}-{train_years[-1]} -> {test_year}] "
        f"OOS_t(Top10/LS)={key_yr_ret:+.4f} | OOS_cum(Top10/LS)={oos_cum:.2f}x | "
        f"Forward_ann(Top10/LS)={key_forward_ann if pd.notna(key_forward_ann) else 'NaN'}"
    )

        # === å»ºä¸€å¼µã€Œè¨“ç·´çª—ç¸½è¦½åœ–ã€ï¼šInner + Forward ç´¯ç© + å¹´åŒ–ï¼ˆTop10/20/30/200 ç–Šåœ¨ä¸€èµ·ï¼‰ ===
    # 1) å–å¾— inner_trajï¼ˆç”¨ç•¶ä»£ GA æœ€ä½³å€‹é«”å°æ‡‰çš„ã€Œæœ€çµ‚æœ€ä½³åƒæ•¸/ç‰¹å¾µã€é‡æ–°å›ç®— inner_yearsï¼‰
    #    è‹¥ä½ åœ¨ ga_optimize_params å…§éƒ¨å·²ç¶“æœ‰ evaluate_gene_traj(gene) å¯å‘¼å«ï¼Œ
    #    é€™è£¡ç›´æ¥ã€Œç”¨æœ€ä½³æ¨¡å‹é‡ç®—ã€ä¸€éå°±å¥½ï¼ˆç­‰åƒ¹ï¼‰ï¼š
    inner_traj = {n:{k:[] for k in KINDs} for n in TOP_NS}
    # ç”¨æœ€ä½³åƒæ•¸ + æ­¤çª—çš„ç‰¹å¾µ cols_for_this_windowï¼Œé‡ç®— inner_years çš„ expanding fitness
    _model_viz = init_model_by_name(MODEL_NAME, best_params)
    for j in range(1, len(train_years)):
        tr_yrs = train_years[:j]
        te_yr  = train_years[j]
        tr_df2 = df[df['year'].isin(tr_yrs)]
        te_df2 = df[df['year'] == te_yr]
        _m, _pred = fit_predict_one_year(_model_viz, tr_df2, te_df2, cols_for_this_window)
        if (_m is None) or (_pred is None):
            for n in TOP_NS:
                for k in KINDs:
                    inner_traj[n][k].append(np.nan)
            continue
        _yr_res = year_strategy_returns(_pred)
        for n in TOP_NS:
            for k in KINDs:
                inner_traj[n][k].append(_yr_res[n][k])

    # 2) forward_returns å·²æ˜¯ {TopN:{kind:[r_t, r_{t+1}, ...]}}
    #    ç›´æ¥é€å»ç•«ç¶œåˆåœ–
    win_viz_dir = os.path.join(result_dir, "window_viz")
    plot_path = _plot_window_all_in_one(
        train_span=f"{train_years[0]}-{train_years[-1]}",
        test_year=test_year,
        inner_years=train_years,
        inner_traj=inner_traj,
        future_years=future_years,
        future_returns_seq=future_returns,
        out_dir=win_viz_dir,
        fname_prefix="WF",
        kinds=tuple(KINDs),
        top_ns=tuple(TOP_NS),
    )
    log.info(f"ğŸ–¼ï¸ Window figure saved: {plot_path}")


    training_rows.append({
        'TrainStart': train_years[0],
        'TrainEnd'  : train_years[-1],
        'TestYear'  : test_year,
        'OOS_Top10_LongShort' : round(float(key_yr_ret), 6) if pd.notna(key_yr_ret) else np.nan,
        'OOS_Cum_Top10_LongShort' : round(float(oos_cum), 6),
        'Forward_Annual_Top10_LongShort' : key_forward_ann,
        'BestParams' : repr(best_params),
        'Selected_Feature_Count': (len(best_cols) if best_cols is not None else np.nan),
        'GA_Fitness' : round(float(best_fit), 6)
    })

outer_pbar.close()

# ========= è¼¸å‡º =========
# (1) OOS ä¸²æ¥æ›²ç·š
plt.figure(figsize=(14,10))
markers = {"long": 'o', "short": 'v', "long_short": 's'}
ls = {"long": '-', "short": '--', "long_short": ':'}
color = {'10':'tab:orange','20':'tab:green','30':'tab:red','200':'tab:purple'}

oos_df = pd.DataFrame({'Year': oos_years})
best_label, best_end = '', -np.inf
for n in TOP_NS:
    for kind in KINDs:
        seq = oos_traj[n][kind]
        cum = np.cumprod([1.0 + (x if pd.notna(x) else 0.0) for x in seq])
        label = f'{kind.capitalize()} Top{n}'
        plt.plot(oos_years, cum, marker=markers[kind], linestyle=ls[kind], color=color[str(n)], label=label)
        oos_df[label] = cum
        if len(cum)>0 and cum[-1] > best_end:
            best_end = float(cum[-1]); best_label = label

plt.title(f'OOS (stitched by year) â€“ Best: {best_label} ({best_end:.2f})')
plt.xlabel('Year'); plt.ylabel('Cumulative (Ã—)')
plt.yscale('log'); plt.grid(True); plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(result_dir, f'{MODEL_NAME}_OOS_stitched.png'))
plt.close()
oos_df.to_csv(os.path.join(result_dir, f'{MODEL_NAME}_OOS_stitched.csv'), index=False)

# (2) Forward å¹´åŒ–å½™ç¸½è¡¨
forward_df = pd.DataFrame(forward_summary_rows)
forward_csv = os.path.join(result_dir, f'{MODEL_NAME}_forward_span_annual.csv')
forward_df.to_csv(forward_csv, index=False)

# (3) ç•¶è¼ªæ‘˜è¦é€å¹´è¡¨
trainwin_csv = os.path.join(result_dir, f'{MODEL_NAME}_training_windows.csv')
pd.DataFrame(training_rows).to_csv(trainwin_csv, index=False)

# (4) ç•« forward å¹´åŒ–ï¼ˆä»¥ long_short/Top10 ç‚ºä¾‹ï¼‰
key_col = 'Top10_long_short_Annual'
if key_col in forward_df.columns:
    plt.figure(figsize=(14,6))
    plt.plot(forward_df['TestSpan'], forward_df[key_col], marker='o')
    plt.title(f'Forward Annualized ({key_col}) per training window')
    plt.xlabel('Forward Span'); plt.ylabel('Annualized Return')
    plt.grid(True); plt.xticks(rotation=45); plt.tight_layout()
    plt.savefig(os.path.join(result_dir, f'{MODEL_NAME}_forward_annual_{key_col}.png'))
    plt.close()

log.info(f'âœ… æˆå“è¼¸å‡ºï¼š{result_dir}')
log.info(f'ğŸ“„ æ—¥èªŒï¼š{log_path}')

import pandas as pd
import yfinance as yf
import os
import json
from tqdm import tqdm
from datetime import datetime
from threading import Lock
from concurrent.futures import ThreadPoolExecutor, as_completed


# === è·¯å¾‘è¨­å®š ===
base_dir = 'AIFinTech/Final/gooddata'
csv_path = os.path.join(base_dir, 'merged_all_metrics.csv')
cache_path = os.path.join(base_dir, 'yahoo_price_cache.json')
output_path = os.path.join(base_dir, 'financial_features_all.csv')
price_dir = os.path.join(base_dir, 'price_csv')
os.makedirs(price_dir, exist_ok=True)

# === è®€å–è³‡æ–™ ===
df = pd.read_csv(csv_path)
df['year'] = df['å¹´'].astype(int)
df['ä»£è™Ÿ'] = df['ä»£è™Ÿ'].astype(str).str.zfill(4)
df = df[df['year'] >= 2000]

# === å¿«å–è¨˜æ†¶é«” ===
if os.path.exists(cache_path):
    with open(cache_path, 'r', encoding='utf-8') as f:
        price_cache = json.load(f)
else:
    price_cache = {}

# === è‚¡ç¥¨æ¸…å–® ===
all_stock_ids = df['ä»£è™Ÿ'].unique()
# price_cache = dict()
today_success_set = set()       # ä»Šå¤©æˆåŠŸæŠ“åˆ°çš„è‚¡ç¥¨
previous_success_set = set()    # å¾æ˜¨å¤©å¿«å–ä¸­è®€åˆ°çš„æ‰€æœ‰è‚¡ç¥¨ä»£è™Ÿ

# é–‹é ­é€™æ®µæ‰æ˜¯å°çš„
if os.path.exists(cache_path):
    with open(cache_path, 'r', encoding='utf-8') as f:
        price_cache = json.load(f)
    previous_success_set = set(k.split("_")[0] for k, v in price_cache.items() if v is not None)
else:
    price_cache = {}
    previous_success_set = set()


price_cache_lock = Lock()  # ğŸ”’ ä¿è­·å…±äº«è³‡æº

print("ğŸ“¦ æŠ“å–æ¯æª”è‚¡ç¥¨ 2000ï½2024åŠ ä¸Š2025YTD æ‰€æœ‰æ”¶ç›¤åƒ¹...")
def fetch_and_process_stock(stock_id):
    global price_cache

    yf_id = f"{stock_id}.TW"
    price_csv_path = os.path.join(price_dir, f'Price_{stock_id}.csv')
    hist = None
    success = False

    # if os.path.exists(price_csv_path):
    #     try:
    #         hist = pd.read_csv(price_csv_path, parse_dates=['Date'], index_col='Date')
    #     except Exception:
    #         os.remove(price_csv_path)

    if hist is None:
        stock_years = df[df['ä»£è™Ÿ'] == stock_id]['year']
        if stock_years.empty:
            return f"âš ï¸ {stock_id} æ²’æœ‰è²¡å ±è³‡æ–™ï¼Œè·³é"

        first_year = 2000
        last_year = 2025
        for end_year in range(last_year, first_year - 1, -1):
            for start_year in range(first_year, end_year + 1):
                start_date = f"{start_year}-01-01"
                end_date = f"{end_year}-12-31"

                try:
                    hist = yf.download(
                        yf_id,
                        start=start_date,
                        end=end_date,
                        auto_adjust=False,
                        progress=False,
                        timeout=20
                    )
                    if hist is not None and not hist.empty:
                        hist.reset_index().to_csv(price_csv_path, index=False)
                        success = True
                        break
                except Exception as e:
                    print(f"âš ï¸ {stock_id} å¾ {start_date} åˆ° {end_date} æŠ“å–å¤±æ•—ï¼š{e}")
                    continue
            if success:
                hist_end_date = hist.index[-1].strftime('%Y-%m-%d')
                print(f"âœ… {stock_id} å¾ {start_date} åˆ° {hist_end_date} æŠ“å–æˆåŠŸ")
                break

    if hist is None or hist.empty:
        return f"âŒ {stock_id} å®Œå…¨æŠ“ä¸åˆ°ä»»ä½•è³‡æ–™"

    try:
        hist = hist if isinstance(hist, pd.DataFrame) else pd.read_csv(price_csv_path, parse_dates=['Date'], index_col='Date')
        available_years = hist.index.year.unique()
        earliest_year = int(available_years.min())
        if pd.isna(earliest_year):
            raise ValueError("No valid year")
    except Exception as e:
        return f"âš ï¸ {stock_id} çš„ price_csv ç„¡æ³•åˆ¤æ–·å¹´ä»½ï¼š{e}"

    local_cache = {}
    for year in range(earliest_year, 2025):
        key = f"{stock_id}_{year}"
        try:
            year_data = hist[str(year)]
            if not year_data.empty:
                last_close = year_data['Close'].iloc[-1].item()
                local_cache[key] = last_close
        except Exception:
            local_cache[key] = None

    with price_cache_lock:
        price_cache.update(local_cache)
        today_success_set.add(stock_id)  # âœ… æˆåŠŸå°±åŠ å…¥ä»Šå¤©æˆåŠŸçš„é›†åˆ


    return f"âœ… {stock_id} è³‡æ–™è™•ç†å®Œæˆ"

# ğŸ¯ å¤šåŸ·è¡Œç·’è·‘èµ·ä¾†
with ThreadPoolExecutor(max_workers=16) as executor:
    futures = {executor.submit(fetch_and_process_stock, sid): sid for sid in all_stock_ids}
    for future in tqdm(as_completed(futures), total=len(futures)):
        result = future.result()
        print(result)

# === å„²å­˜å¿«å–ï¼ˆå¯çºŒè·‘ï¼‰===
with open(cache_path, 'w', encoding='utf-8') as f:
    json.dump(price_cache, f, ensure_ascii=False, indent=2)

# === ç”¢ç”ŸæˆåŠŸèˆ‡å¤±æ•—å ±å‘Š ===
newly_fetched = today_success_set - previous_success_set
missing_today = previous_success_set - today_success_set

print(f"\nğŸ†• ä»Šå¤©æ–°å¢æˆåŠŸçš„è‚¡ç¥¨ï¼ˆ{len(newly_fetched)} æª”ï¼‰: {sorted(newly_fetched)}")
print(f"âš ï¸ æœ‰æŠ“éä½†ä»Šå¤©æ²’æŠ“åˆ°çš„è‚¡ç¥¨ï¼ˆ{len(missing_today)} æª”ï¼‰: {sorted(missing_today)}")
print(f"ğŸ“Š ç¸½å…±æŠ“å–äº† {len(price_cache)} æª”è‚¡ç¥¨çš„æ”¶ç›¤åƒ¹")
# === åŠ å…¥æ”¶ç›¤åƒ¹æ¬„ä½åˆ° df ===
df['closing_price_year'] = df.apply(
    lambda x: price_cache.get(f"{x['ä»£è™Ÿ']}_{x['year']}"), axis=1
)

# âœ… åˆ°é€™è£¡å°±å¯ä»¥æ¥ä¸‹ä¾†åšæŒ‡æ¨™é‹ç®—å›‰ï½
print("ğŸ‰ æ‰€æœ‰è‚¡ç¥¨æ­·å²æ”¶ç›¤åƒ¹æŠ“å–å®Œæˆï¼Œå¯é€²è¡Œç‰¹å¾µé‹ç®—äº†å–µâ™¡")
# ğŸ’¡ åªä¿ç•™æœ‰æˆåŠŸæŠ“åˆ°æ”¶ç›¤åƒ¹çš„è³‡æ–™ï¼ˆé˜²æ­¢å¾ŒçºŒçˆ†éŒ¯ï¼‰
df = df[df['closing_price_year'].notna()]


# === è¨ˆç®—ç‰¹å¾µ ===
df['market_cap_mil'] = df['closing_price_year'] * df['ç™¼è¡Œé‡(è¬å¼µ)'] * 1000
df['pb_ratio'] = df['closing_price_year'] / (df['è‚¡æ±æ¬Šç›Šç¸½é¡(å„„)'] * 100 / df['ç™¼è¡Œé‡(è¬å¼µ)'])
market_cap_mil = df['market_cap_mil']
revenue_mil = df['ç‡Ÿæ”¶(å„„)'] * 100
df['ps_ratio'] = df['market_cap_mil'] / (df['ç‡Ÿæ”¶(å„„)'] * 100)
df['roe_m'] = df['æ·¨åˆ©ç‡(%)'] / 100 * df['ç‡Ÿæ”¶(å„„)'] / df['è‚¡æ±æ¬Šç›Šç¸½é¡(å„„)']
df['opm'] = df['ç‡Ÿç›Š(å„„)'] / df['ç‡Ÿæ”¶(å„„)']
df['npm'] = df['æ·¨åˆ©ç‡(%)'] / 100
df['roa'] = df['ROA(%)'] / 100
df['debt_to_equity'] = df['è² å‚µç¸½é¡(å„„)'] / df['è‚¡æ±æ¬Šç›Šç¸½é¡(å„„)']
df['current_ratio_m'] = df['æµå‹•è³‡ç”¢å°æµå‹•è² å‚µ(%)'] / 100
df['quick_ratio_m'] = df['é€Ÿå‹•è³‡ç”¢å°æµå‹•è² å‚µ(%)'] / 100
df['inventory_turnover_m'] = df['å­˜è²¨é€±è½‰ç‡']
df['ar_turnover_m'] = df['æ‡‰æ”¶å¸³æ¬¾é€±è½‰ç‡']
df = df.sort_values(by=['ä»£è™Ÿ', 'year'])
df['op_growth_m'] = df.groupby('ä»£è™Ÿ')['ç‡Ÿç›Š(å„„)'].pct_change()
df['net_income_growth_m'] = df.groupby('ä»£è™Ÿ')['æ·¨åˆ©ç‡(%)'].pct_change()
df['future_price'] = df.groupby('ä»£è™Ÿ')['closing_price_year'].shift(-1)
df['return'] = (df['future_price'] / df['closing_price_year']) - 1
df['return_label'] = (df['return'] > 0).astype(int)
df.drop(columns=['future_price'], inplace=True)

# === è¼¸å‡ºçµæœ ===
df.to_csv(output_path, index=False, encoding='utf-8-sig')
print(f"\nğŸ‰ æ”¶ç›¤åƒ¹è¨ˆç®—å®Œæˆï¼š{output_path}ï¼Œé‚„è‡ªå‹•å¿«å–äº†å–µâ™¡")
print("æ¥ä¸‹ä¾†å‰å¾€merge_and_compute_featuresåˆä½µç‰¹å¾µå·¥ç¨‹çš„éƒ¨åˆ†å–µâ™¡")

# -*- coding: utf-8 -*-
import os
import re
from glob import glob
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
import numpy as np
import psycopg2
import psycopg2.extras
from psycopg2.extras import execute_values
import yfinance as yf
from tqdm import tqdm
from dotenv import load_dotenv

load_dotenv()
# === DB é€£ç·šè¨­å®š ===
DB_CONFIG = {
    "dbname": os.getenv("DBNAME"),
    "user": os.getenv("USER"),
    "password": os.getenv("PASSWORD"),
    "host": os.getenv("HOST"),
    "port": os.getenv("PORT")
}
print(f"ğŸ”— é€£ç·šåˆ°è³‡æ–™åº« {DB_CONFIG['dbname']} åœ¨ {DB_CONFIG['host']}:{DB_CONFIG['port']}")
def get_conn():
    return psycopg2.connect(**DB_CONFIG)

# === Step 1: è®€å– StockList*.csv â†’ å¯«å…¥ stocks / annual_financials ===
def import_financials_from_csv(file_dir):
    # 1) æ”¶é›†é•·è¡¨è³‡æ–™
    file_paths = sorted(glob(os.path.join(file_dir, 'StockList*.csv')))
    long_data = []
    year_metric_pat = re.compile(r"(\d{4})(?:å¹´åº¦)?(.+)")

    for fp in file_paths:
        df = pd.read_csv(fp, encoding='utf-8-sig')
        if 'æ’å' in df.columns:
            df = df.drop(columns=['æ’å'])
        if not {'ä»£è™Ÿ','åç¨±'}.issubset(df.columns):
            raise ValueError(f'æª”æ¡ˆ {os.path.basename(fp)} ç¼ºå°‘å¿…è¦æ¬„ä½ï¼šä»£è™Ÿ/åç¨±')

        id_name_cols = ['ä»£è™Ÿ','åç¨±']
        data_cols = [c for c in df.columns if c not in id_name_cols]

        # å°‡æ¯å€‹ã€ŒYYYY æŒ‡æ¨™ã€æ‹†æˆå¹´èˆ‡æŒ‡æ¨™
        for col in data_cols:
            m = year_metric_pat.match(col)
            if not m:
                continue
            year = int(m.group(1))
            metric = m.group(2).strip()
            for _, row in df.iterrows():
                raw_code = row['ä»£è™Ÿ']
                # å…¼å®¹ ="2330" / 2330 / '2330'
                if isinstance(raw_code, str) and raw_code.startswith('="'):
                    code = raw_code[2:-1]
                else:
                    code = str(raw_code)
                code = re.sub(r'\D', '', code).zfill(4)

                long_data.append({
                    'ä»£è™Ÿ': code,
                    'åç¨±': row['åç¨±'],
                    'å¹´': year,
                    'æŒ‡æ¨™': metric,
                    'å€¼': row[col]
                })

    if not long_data:
        raise ValueError(f'âŒ æ²’æœ‰å¾ {file_dir} çš„ StockList*.csv è§£æåˆ°ä»»ä½•è²¡å ±æ¬„ä½ï¼ˆè«‹æª¢æŸ¥æ¬„ä½æ˜¯å¦ç‚ºã€Œ2022 ç‡Ÿæ”¶(å„„)ã€é€™ç¨®æ ¼å¼ï¼‰')

    # 2) é•·â†’å¯¬ï¼ˆä¿ç•™ç¼ºå€¼ï¼Œå¾Œé¢å¯« DB æœƒè®Š NULLï¼‰
    long_df = pd.DataFrame(long_data)
    # æ•¸å­—æ¸…æ´—ï¼šç§»é™¤é€—è™Ÿï¼Œç©ºå­—ä¸²â†’NAï¼Œæ‹¬è™Ÿè² æ•¸ (123) â†’ -123
    def _to_float(x):
        if pd.isna(x):
            return np.nan
        s = str(x).strip().replace(',', '')
        if s == '':
            return np.nan
        m = re.match(r'^\((\-?\d+(?:\.\d+)?)\)$', s)  # (123.4)
        if m:
            return -float(m.group(1))
        try:
            return float(s)
        except:
            return np.nan
    long_df['å€¼'] = long_df['å€¼'].map(_to_float)

    pivot_df = long_df.pivot_table(
        index=['ä»£è™Ÿ','åç¨±','å¹´'],
        columns='æŒ‡æ¨™',
        values='å€¼',
        aggfunc='first'
    ).reset_index()
    pivot_df.dropna(how='any', inplace=True)  # ç§»é™¤æœ‰ç©ºå€¼çš„åˆ—
    print(f"ğŸ“Š CSV æª” {len(file_paths)} å€‹ â†’ é•·è¡¨ {len(long_df):,} ç­† â†’ å¯¬è¡¨ {len(pivot_df):,} åˆ—")

    # 3) å…ˆ upsert stocksï¼ˆä»¥å››ç¢¼ä»£è™Ÿç•¶ä¸»éµï¼Œmarket=TWï¼‰
    with get_conn() as conn, conn.cursor() as cur:
        stocks = (
            pivot_df[['ä»£è™Ÿ','åç¨±']].drop_duplicates()
            .assign(
                market='TW',
                yf_symbol=lambda x: x['ä»£è™Ÿ'].astype(str).str.zfill(4) + '.TW'
            )
            .rename(columns={'ä»£è™Ÿ':'stock_id','åç¨±':'name'})
        )
        # stock_id è½‰ç´”æ•¸å­— BIGINT
        stocks['stock_id'] = stocks['stock_id'].astype(str).str.extract(r'(\d+)')[0].astype('int64')

        psycopg2.extras.execute_batch(
            cur,
            """
            INSERT INTO stocks(stock_id, market, name, yf_symbol)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (stock_id, market) DO UPDATE SET
                name = EXCLUDED.name,
                yf_symbol = EXCLUDED.yf_symbol
            """,
            list(stocks[['stock_id','market','name','yf_symbol']].itertuples(index=False, name=None))
        )

        # å»ºç«‹ 'å››ç¢¼å­—ä¸²' -> int çš„ map
        cur.execute("SELECT stock_id FROM stocks WHERE market='TW'")
        code2id = {str(sid).zfill(4): int(sid) for (sid,) in cur.fetchall()}

        # 4) æº–å‚™ annual_financials çš„æ¬„ä½å°ç…§ï¼ˆCSVâ†’DB æ¬„åï¼‰
        rename_map = {
            'ç‡Ÿæ”¶(å„„)': 'ç‡Ÿæ”¶_å„„',
            'ç‡Ÿç›Š(å„„)': 'ç‡Ÿç›Š_å„„',
            'æ·¨åˆ©ç‡(%)': 'æ·¨åˆ©ç‡_pct',
            'æ·¨åˆ©å¢æ¸›(%)': 'æ·¨åˆ©å¢æ¸›_pct',
            'ROA(%)': 'roa_pct',
            'ç™¼è¡Œé‡(è¬å¼µ)': 'ç™¼è¡Œé‡_è¬å¼µ',
            'è‚¡æ±æ¬Šç›Šç¸½é¡(å„„)': 'è‚¡æ±æ¬Šç›Šç¸½é¡_å„„',
            'è² å‚µç¸½é¡(å„„)': 'è² å‚µç¸½é¡_å„„',
            'æµå‹•è³‡ç”¢å°æµå‹•è² å‚µ(%)': 'æµå‹•è³‡ç”¢å°æµå‹•è² å‚µ_pct',
            'é€Ÿå‹•è³‡ç”¢å°æµå‹•è² å‚µ(%)': 'é€Ÿå‹•è³‡ç”¢å°æµå‹•è² å‚µ_pct',
            'å­˜è²¨é€±è½‰ç‡': 'å­˜è²¨é€±è½‰ç‡',
            'æ‡‰æ”¶å¸³æ¬¾é€±è½‰ç‡': 'æ‡‰æ”¶å¸³æ¬¾é€±è½‰ç‡',
        }

        fin = pivot_df.rename(columns=rename_map).copy()
        fin.rename(columns={'å¹´':'year'}, inplace=True)
        fin['stock_id'] = fin['ä»£è™Ÿ'].astype(str).str.zfill(4).map(code2id).astype('Int64')

        missing_codes = fin[fin['stock_id'].isna()]['ä»£è™Ÿ'].unique().tolist()
        if missing_codes:
            raise ValueError(f"âŒ ä¸‹åˆ—ä»£è™Ÿåœ¨ stocks æ‰¾ä¸åˆ°å°æ‡‰ stock_idï¼š{sorted(missing_codes)}")

        # å– DB çœŸå¯¦æ¬„ä½ï¼Œç¢ºä¿åªæ’å­˜åœ¨çš„æ¬„ä½
        cur.execute("""
            SELECT column_name
            FROM information_schema.columns
            WHERE table_schema='public' AND table_name='annual_financials'
            ORDER BY ordinal_position
        """)
        db_cols = [r[0] for r in cur.fetchall()]

        # æˆ‘å€‘è¦å¯«å…¥çš„æ¬„ä½ï¼šDB æœ‰ã€ä¸” fin æœ‰è³‡æ–™çš„æ¬„ä½
        candidate_cols = ['stock_id','year'] + [c for c in rename_map.values()]
        insert_cols = [c for c in db_cols if c in candidate_cols]

        # é¡å¤–çµ±è¨ˆï¼šCSV æœ‰ä½† DB æ²’æœ‰çš„æŒ‡æ¨™ï¼ˆåƒ…æç¤ºï¼‰
        csv_metrics = set(col for col in pivot_df.columns if col not in ['ä»£è™Ÿ','åç¨±','å¹´'])
        mapped_metrics = set(rename_map.keys())
        not_in_db = sorted((csv_metrics - mapped_metrics))
        if not_in_db:
            print(f"â„¹ï¸ é€™äº› CSV æŒ‡æ¨™ç›®å‰æœªå¯«å…¥ï¼ˆDB æœªå»ºæˆ–æœªæ˜ å°„ï¼‰ï¼š{not_in_db[:12]}{' ...' if len(not_in_db)>12 else ''}")

        # çµ„è³‡æ–™ï¼ˆNaNâ†’Noneï¼‰
        fin = fin.dropna(how='any')
        rows = [tuple(int(val) if isinstance(val, np.int64) else val for val in fin.loc[i, insert_cols].values) for i in fin.index]

        if not rows:
            raise ValueError("âŒ annual_financials æ²’æœ‰å¯å¯«å…¥çš„è³‡æ–™åˆ—")

        # å‹•æ…‹ upsert
        cols_sql = ','.join(f'"{c}"' for c in insert_cols)
        placeholders = ','.join(['%s']*len(insert_cols))
        update_sql = ','.join(f'"{c}"=EXCLUDED."{c}"' for c in insert_cols if c not in ('stock_id','year'))

        psycopg2.extras.execute_batch(
            cur,
            f"""
            INSERT INTO annual_financials({cols_sql})
            VALUES ({placeholders})
            ON CONFLICT (stock_id, year) DO UPDATE SET
            {update_sql}
            """,
            rows,
            page_size=500
        )

    print(f"âœ… åŒ¯å…¥å¹´åº¦è²¡å ±å®Œæˆï¼š{len(pivot_df):,} åˆ—ã€å¯«å…¥æ¬„ä½ {len(insert_cols)} å€‹")
    return code2id



# === Step 2: æŠ“æ—¥åƒ¹ â†’ daily_prices ===
PRICE_DIR = os.path.join(os.path.dirname(__file__), 'price_csv')
CHUNK_ROWS = 50_000   # ç´¯ç©åˆ°é€™éº¼å¤š rows å°±æ‰¹æ¬¡å¯«å…¥ä¸€æ¬¡ï¼ˆå¯èª¿ï¼‰

def _to_float_or_none(x):
    if pd.isna(x): 
        return None
    s = str(x).strip().replace(',', '')
    if s == '': 
        return None
    try:
        return float(s)
    except:
        return None

def load_price_csv(stock_id: int):
    """
    è®€å–å–®ä¸€è‚¡ç¥¨çš„åƒ¹æ ¼ CSVï¼Œè½‰æˆå¯ç›´æ¥å¯« DB çš„ rows listã€‚
    åƒ…åš I/O+æ¸…æ´—ï¼Œä¸é€²è¡Œä»»ä½• DB æ“ä½œã€‚
    å›å‚³: List[Tuple(stock_id, dt, open, high, low, close, adj_close, volume)]
    """
    # æ”¯æ´ 2330 èˆ‡ 02330 å…©ç¨®å‘½åï¼ˆè¦–ä½ å¯¦éš›æª”åæƒ…æ³ï¼‰
    candidates = [
        os.path.join(PRICE_DIR, f'Price_{stock_id}.csv'),
    ]
    price_file = next((p for p in candidates if os.path.exists(p)), None)
    if not price_file:
        return [], f"âŒ Price_{stock_id}.csv ä¸å­˜åœ¨"

    try:
        df = pd.read_csv(price_file, dtype=str)
        # å¿…è¦æ¬„ä½æª¢æŸ¥
        need_cols = {'Date','Open','High','Low','Close','Volume'}
        if not need_cols.issubset(df.columns):
            return [], f"âš ï¸ {os.path.basename(price_file)} æ¬„ä½ç¼ºå¤±ï¼š{need_cols - set(df.columns)}"

        # è½‰å‹
        df['dt'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
        df = df.dropna(subset=['dt'])

        open_p   = df['Open'].map(_to_float_or_none)
        high_p   = df['High'].map(_to_float_or_none)
        low_p    = df['Low'].map(_to_float_or_none)
        close_p  = df['Close'].map(_to_float_or_none)
        adj_close= df['Adj Close'].map(_to_float_or_none) if 'Adj Close' in df.columns else close_p
        # Volume å¯èƒ½æœ‰å°æ•¸/ç©ºå­—ä¸²ï¼Œè½‰ int æˆ– None
        vol = []
        for v in df['Volume'].fillna(''):
            vv = str(v).replace(',', '').strip()
            if vv == '':
                vol.append(None)
            else:
                try:
                    vol.append(int(float(vv)))
                except:
                    vol.append(None)

        # ä¿ç•™æœ€å¾Œä¸€æ¬¡å‡ºç¾çš„è©²æ—¥ï¼ˆè‹¥æª”æ¡ˆå…§æœ‰é‡è¤‡æ—¥æœŸï¼‰
        out = {}
        for d, o, h, l, c, a, v in zip(df['dt'], open_p, high_p, low_p, close_p, adj_close, vol):
            out[d] = (int(stock_id), d, o, h, l, c, a, v)

        rows = list(out.values())
        return rows, f"âœ… {stock_id} è®€å…¥ {len(rows)} åˆ—"
    except Exception as e:
        return [], f"âš ï¸ {stock_id} è®€æª”å¤±æ•—ï¼š{e}"

def write_prices_to_db(rows):
    """
    å–®åŸ·è¡Œç·’æ‰¹æ¬¡å¯« DBã€‚ä½¿ç”¨ execute_values ä¸€æ¬¡å¡å¤šåˆ—ï¼‹ON CONFLICT UPSERTã€‚
    """
    if not rows:
        return 0
    sql = """
        INSERT INTO daily_prices
            (stock_id, dt, open_p, high_p, low_p, close_p, adj_close, volume)
        VALUES %s
        ON CONFLICT (stock_id, dt) DO UPDATE SET
            open_p = EXCLUDED.open_p,
            high_p = EXCLUDED.high_p,
            low_p  = EXCLUDED.low_p,
            close_p= EXCLUDED.close_p,
            adj_close = EXCLUDED.adj_close,
            volume = EXCLUDED.volume
    """
    with get_conn() as conn, conn.cursor() as cur:
        execute_values(cur, sql, rows, page_size=10_000)
    return len(rows)

def parallel_import_prices(code2id: dict, max_workers=16, chunk_rows=CHUNK_ROWS):
    """
    å¤šåŸ·è¡Œç·’è®€ CSV -> ä¸»åŸ·è¡Œç·’ç´¯ç©åˆ°ä¸€å®šè¡Œæ•¸å°±æ‰¹æ¬¡å¯«å…¥ DBã€‚
    code2id: {'2330': 2330, ...} ï¼ˆkeyä¸ä½¿ç”¨ï¼Œä¸»è¦æ˜¯ value ç‚ºæ•´æ•¸ stock_idï¼‰
    """
    # åªå–æ•´æ•¸ stock_id åˆ—è¡¨
    stock_ids = list(set(int(v) for v in code2id.values()))
    rows_buffer = []
    ok, miss = 0, 0

    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futures = [ex.submit(load_price_csv, sid) for sid in stock_ids]
        for fut in tqdm(as_completed(futures), total=len(futures)):
            rows, msg = fut.result()
            print(msg)
            if rows:
                rows_buffer.extend(rows)
                # ç´¯ç©å¤ å¤§å°±å¯«ä¸€æ¬¡
                if len(rows_buffer) >= chunk_rows:
                    n = write_prices_to_db(rows_buffer)
                    ok += n
                    rows_buffer.clear()
            else:
                miss += 1

    # æ”¶å°¾
    if rows_buffer:
        n = write_prices_to_db(rows_buffer)
        ok += n

    print(f"âœ… daily_prices åŒ¯å…¥å®Œæˆï¼šå¯«å…¥ {ok:,} åˆ—ï¼Œç¼ºæª”/å¤±æ•— {miss} æª”")


# === Step 3: è¨ˆç®—ç‰¹å¾µ â†’ financial_features ===
def compute_and_store_features():
    with get_conn() as conn:
        df = pd.read_sql("""
            SELECT a.*, v.closing_price_year
            FROM annual_financials a
            LEFT JOIN v_year_end_close v
            ON a.stock_id = v.stock_id AND a.year = v.year
            WHERE a.year >= 2000
            ORDER BY a.stock_id, a.year
        """, conn)

    df['market_cap_mil'] = df['closing_price_year'] * df['ç™¼è¡Œé‡(è¬å¼µ)'] * 1000
    df['pb_ratio'] = df['closing_price_year'] / (df['è‚¡æ±æ¬Šç›Šç¸½é¡(å„„)'] * 100 / df['ç™¼è¡Œé‡(è¬å¼µ)'])
    df['ps_ratio'] = df['market_cap_mil'] / (df['ç‡Ÿæ”¶(å„„)'] * 100)
    df['roe_m'] = df['æ·¨åˆ©ç‡(%)']/100 * df['ç‡Ÿæ”¶(å„„)'] / df['è‚¡æ±æ¬Šç›Šç¸½é¡(å„„)']
    df['opm'] = df['ç‡Ÿç›Š(å„„)'] / df['ç‡Ÿæ”¶(å„„)']
    df['npm'] = df['æ·¨åˆ©ç‡(%)']/100
    df['roa'] = df['ROA(%)']/100
    df['debt_to_equity'] = df['è² å‚µç¸½é¡(å„„)'] / df['è‚¡æ±æ¬Šç›Šç¸½é¡(å„„)']
    df['current_ratio_m'] = df['æµå‹•è³‡ç”¢å°æµå‹•è² å‚µ(%)']/100
    df['quick_ratio_m'] = df['é€Ÿå‹•è³‡ç”¢å°æµå‹•è² å‚µ(%)']/100
    df['inventory_turnover_m'] = df['å­˜è²¨é€±è½‰ç‡']
    df['ar_turnover_m'] = df['æ‡‰æ”¶å¸³æ¬¾é€±è½‰ç‡']

    df = df.sort_values(['stock_id', 'year'])
    df['op_growth_m'] = df.groupby('stock_id')['ç‡Ÿç›Š(å„„)'].pct_change()
    df['net_income_growth_m'] = df.groupby('stock_id')['æ·¨åˆ©ç‡(%)'].pct_change()
    df['future_price'] = df.groupby('stock_id')['closing_price_year'].shift(-1)
    df['return_1y'] = (df['future_price'] / df['closing_price_year']) - 1
    df['return_label'] = (df['return_1y'] > 0).astype(int)

    cols = [
        'stock_id','year','closing_price_year','market_cap_mil','pb_ratio','ps_ratio',
        'roe_m','opm','npm','roa','debt_to_equity','current_ratio_m','quick_ratio_m',
        'inventory_turnover_m','ar_turnover_m','op_growth_m','net_income_growth_m',
        'return_1y','return_label'
    ]
    out = df[cols].dropna(subset=['closing_price_year'])

    with get_conn() as conn, conn.cursor() as cur:
        psycopg2.extras.execute_batch(cur, f"""
            INSERT INTO financial_features({','.join(cols)})
            VALUES ({','.join(['%s']*len(cols))})
            ON CONFLICT (stock_id, year) DO UPDATE SET
            {','.join([f"{c}=EXCLUDED.{c}" for c in cols[2:]])}
        """, list(out.itertuples(index=False, name=None)))
    print("âœ… financial_features æ›´æ–°å®Œæˆ")

# === Main ===
if __name__ == "__main__":
    base_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)))
    print(f"ğŸ“‚ ä½¿ç”¨ç›®éŒ„ï¼š{base_dir}")
    code2id = import_financials_from_csv(base_dir)
    parallel_import_prices(code2id, max_workers=16, chunk_rows=50_000)
    # compute_and_store_features()
    print("ğŸ‰ buildDB å…¨æµç¨‹å®Œæˆå–µâ™¡")

from hmm import GaussianHMM
import os
import pandas as pd
from sklearn.preprocessing import StandardScaler
import torch
import numpy as np
from sklearn.preprocessing import (
    StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler,
    Normalizer, PowerTransformer, QuantileTransformer
)
# æª”æ¡ˆèˆ‡è³‡æ–™å¤¾è¨­å®š
base_dir = os.path.dirname(os.path.abspath(__file__))
script_name = os.path.splitext(os.path.basename(__file__))[0]
result_dir = os.path.join(base_dir, "result", f"{script_name}_result")
os.makedirs(result_dir, exist_ok=True)

input_path = os.path.join(base_dir, "BITSTAMP_BTCUSD,240more.csv")
output_path = os.path.join(result_dir, script_name + "_output.csv")

# è®€è³‡æ–™
df = pd.read_csv(input_path)
df['next_return'] = df['close'].pct_change().shift(-1).fillna(0)
# ğŸ§  é¸ä½ æƒ³è¦çš„æŠ€è¡“æŒ‡æ¨™æ¬„ä½ï¼ˆå¤šä¸€é»æ²’é—œä¿‚ï¼‰
df = df.dropna(axis=1)
features = df.drop(columns=['time','next_return']) \
                  .select_dtypes(include=[np.number]).columns.tolist()
# df = df.dropna(subset=features).reset_index(drop=True)
# å»ºç«‹æ¨™æº–åŒ–ç‰ˆæœ¬
scalers = {
    'z': StandardScaler(),
    'minmax': MinMaxScaler(),
    'maxabs': MaxAbsScaler(),
    'robust': RobustScaler(),
    'l2norm': Normalizer(norm='l2'),
    'power': PowerTransformer(method='yeo-johnson'),
    'quantile': QuantileTransformer(output_distribution='normal', n_quantiles=100)
}
# å°æ¯å€‹ç‰¹å¾µæ¬„ä½é€²è¡Œæ¨™æº–åŒ–
print("ğŸ” æ­£åœ¨æ¨™æº–åŒ–ç‰¹å¾µæ¬„ä½...")
for name, scaler in scalers.items():
    try:
        scaled = scaler.fit_transform(df[features])
        scaled_df = pd.DataFrame(scaled, columns=[f"{col}_{name}" for col in features])
        df = pd.concat([df.reset_index(drop=True), scaled_df.reset_index(drop=True)], axis=1)
    except Exception as e:
        print(f"âš ï¸ {name} scaling failed: {e}")
# åŠ å…¥è®ŠåŒ–ç‡ï¼ˆå·®åˆ†æ¯”ä¾‹è®ŠåŒ–ï¼‰1~4éš
# åŠ å…¥è®ŠåŒ–ç‡ï¼ˆè‡ªè¨‚å‰ä¸€ç­†ç‚º 0 çš„è¡Œç‚ºï¼‰
for col in features:
    for k in range(1, 5):
        prev = df[col].shift(k)
        curr = df[col]
        # å¦‚æœ prev==0ï¼Œè®“å®ƒè®Šæˆæ¥µå°å€¼ä»¥é¿å…é™¤ä»¥ 0ï¼›æˆ–ä½ å¯ä»¥è‡ªè¨‚ç‚º 1.0
        safe_prev = prev.replace(0, np.nan)
        change = (curr - prev) / safe_prev
        df[f"{col}_chg{k}"] = change.fillna(0)  # ä¹Ÿå¯ä»¥ç”¨ .fillna(1.0)

select_features = [col for col in df.columns if col != 'time']
print(f"ğŸ±â€ğŸ‘¤ ç¾åœ¨ df ä¸­å…±æœ‰ {len(select_features)} æ¬„ä½ï¼š")
print(select_features)

print(f"ğŸ“Š ä½¿ç”¨çš„ç‰¹å¾µæ¬„ä½ï¼š{select_features}")


# ğŸš€ åˆå§‹åŒ– GPU ä¸Šçš„ HMM æ¨¡å‹

for i in range(2, 31):
    # ğŸ§ª æ¨™æº–åŒ– & æ”¾é€² CUDA
    X_np = scaler.fit_transform(df[features].values)
    X = torch.tensor(X_np, dtype=torch.float32, device='cuda')

    model = GaussianHMM(n_states=i, n_features=X.shape[1], device='cuda')

    # ğŸ“ˆ è·‘ Viterbi é æ¸¬éš±è—ç‹€æ…‹
    states = model.viterbi(X)

    # ğŸ¾ å­˜å›åŸå§‹ DataFrame ä¸¦è¼¸å‡º
    df['hidden_state'] = states.cpu().numpy()
    df.to_csv(output_path, index=False)

    print(f"âœ… å…¨éƒ¨åœ¨ GPU ä¸Šå®Œæˆï¼çµæœå„²å­˜åˆ°ï¼š{output_path}")
